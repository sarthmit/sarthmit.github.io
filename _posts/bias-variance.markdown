---
layout: post
title:  "A Modern Take on the Bias-Variance Tradeoff in Neural Networks"
date:   2018-10-19 00:00:00 +00:00
image: /images/bias-variance.png
categories: research
author: "Sarthak Mittal"
authors: "Brady Neal, <strong>Sarthak Mittal</strong>, Aristide Baratin, Vinayak Tantia, Matthew Scicluna, Simone Lacoste-Julien, Ioannis Mitliagkas"
venue: "ICML 2019 Deep Phenomena Workshop"
arxiv: https://arxiv.org/abs/1810.08591
---
We study overfitting and generalization in overparameterized neural networks through the lens of the bias-variance tradeoff. We empirically uncover that with increasing width of a single-layered neural network, both bias and variance decrease while with increasing depth, variance increases. We further provide a decomposition of variance into two further terms: variance due to optimization and sampling respectively.
